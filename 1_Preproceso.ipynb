{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "1_Preproceso.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn1SfS_F7neP"
      },
      "source": [
        "# 1. Preproceso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpBl13Yw7ta8"
      },
      "source": [
        "## 1.1 Imports y carga de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWnAOXwg9rZ3"
      },
      "source": [
        "Al comienzo de este notebook, se ejecutará todos los imports usados en él, y el dataset utilizado para llevar a cabo el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2YbMPyG7ig_",
        "outputId": "47e9d121-6ae0-453c-e6e2-efc3532b7e93"
      },
      "source": [
        "#Imports y carga del dataset\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import math\n",
        "import ast\n",
        "import io\n",
        "import re\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "#pd.set_option(\"display.max_rows\", None)\n",
        "\n",
        "with open(\"movies_dataset/movies_metadata.csv\", \"r\", encoding='utf-8') as f:\n",
        "    df_raw = pd.read_csv(f, encoding=\"utf-8\")\n",
        "    print(\"Dataset loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/hector/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/hector/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/hector/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPWxYp1W_JKv"
      },
      "source": [
        "## 1.2 Eliminación de columnas no usadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is7Lr6DG_bJt"
      },
      "source": [
        "Vamos a procesar todas las columnas del dataset y construir un dataframe nuevo.\r\n",
        "\r\n",
        "Las columnas que hemos considerado innecesarias para incluir son:\r\n",
        "\r\n",
        "* ``homepage``\r\n",
        "* ``ìmdb_id``\r\n",
        "* ``original_title``\r\n",
        "* ``poster_path``\r\n",
        "* ``status``\r\n",
        "* ``video``\r\n",
        "* ``id``\r\n",
        "* ``popularity``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ev0ktFP7ihH",
        "outputId": "898ade82-6333-4f20-fffb-5c75bf8aee10"
      },
      "source": [
        "exclude = [\"homepage\", \"imdb_id\", \"original_title\", \"poster_path\", \"status\", \"video\", \"id\", \"popularity\"] \n",
        "df = df_raw.loc[:, df_raw.columns.difference(exclude)]\n",
        "print(\"Columnas excluidas\")\n",
        "\n",
        "preprocessed = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Columnas excluidas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_BemrkxGHkw"
      },
      "source": [
        "Una vez eliminada estas columnas, se comprueba que columnas son las que se van a procesar y cuales tienen algún valor nulo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-ch1sNL7ihI",
        "outputId": "1cd8ee5f-306c-4aca-a151-42ca6aa79b0c"
      },
      "source": [
        "#Comprobación de valores nulos\n",
        "\n",
        "print(pd.isnull(df).any())\n",
        "print()\n",
        "print(\"Filas totales:\", len(df))\n",
        "print(\"Filas con algún valor nulo:\", len([x for x in df.isnull().any(axis=1) if x]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adult                    False\n",
            "belongs_to_collection     True\n",
            "budget                   False\n",
            "genres                   False\n",
            "original_language         True\n",
            "overview                  True\n",
            "production_companies      True\n",
            "production_countries      True\n",
            "release_date              True\n",
            "revenue                   True\n",
            "runtime                   True\n",
            "spoken_languages          True\n",
            "tagline                   True\n",
            "title                     True\n",
            "vote_average              True\n",
            "vote_count                True\n",
            "dtype: bool\n",
            "\n",
            "Filas totales: 45466\n",
            "Filas con algún valor nulo: 42894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pJnLJBLGV3Z"
      },
      "source": [
        "## 1.3 Procesamiento de columnas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGKYnsI1Gcrv"
      },
      "source": [
        "### 1.3.1 Adult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sBHiQamGhuH"
      },
      "source": [
        "Aqui observamos que hay valores no booleanos que debemos eliminar, y además observamos que las películas con valor True son muy escasas en comparación con las que tienen valor False, por lo que se procederá a eliminar las filas anómalas y quitar la columna ``adult``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfjW3j4q7ihJ",
        "outputId": "48572e2d-4711-4748-ab28-ec1ed2d92c39"
      },
      "source": [
        "print(df[\"adult\"].value_counts())\n",
        "print()\n",
        "\n",
        "drop_list = []\n",
        "for i in range(len(df)):\n",
        "    if df[\"adult\"][i] != \"False\":\n",
        "        drop_list.append(i)\n",
        "\n",
        "df.drop(index=drop_list, inplace=True)\n",
        "\n",
        "print(df[\"adult\"].value_counts())\n",
        "\n",
        "#No añadimos la columna al nuevo dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False                                                                                                                             45454\n",
            "True                                                                                                                                  9\n",
            " - Written by Ørnås                                                                                                                   1\n",
            " Rune Balot goes to a casino connected to the October corporation to try to wrap up her case once and for all.                        1\n",
            " Avalanche Sharks tells the story of a bikini contest that turns into a horrifying affair when it is hit by a shark avalanche.        1\n",
            "Name: adult, dtype: int64\n",
            "\n",
            "False    45454\n",
            "Name: adult, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQOhEFw2Tqff"
      },
      "source": [
        "### 1.3.2 Title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cHDwgWKdINs"
      },
      "source": [
        "Antes de procesar esta columna, se pasará a definir una serie de funciones que nos servirán para procesar aquellas carácterísticas que están formadas por lenguaje natural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWe3Wo7-7ihK"
      },
      "source": [
        "# Definicion de funciones para el procesamiento de lenguaje natural\n",
        "\n",
        "replaces = [(\"i'm\", \"i am\"), (\"you're\", \"you are\"), (\"we're\", \"we are\"), (\"they're\", \"they are\"),\n",
        "            (\"that's\", \"that is\"), (\"there's\", \"there is\"), (\"who's\", \"who is\"), (\"what's\", \"what is\"),\n",
        "            \n",
        "            (\"isn't\", \"is not\"), (\"aren't\", \"are not\"), (\"can't\", \"cannot\"), (\"haven't\", \"have not\"),\n",
        "            (\"won't\", \"will not\"), (\"doesn't\", \"does not\"), (\"don't\", \"do not\"), (\"didn't\", \"did not\"),\n",
        "            (\"couldn't\", \"could not\"), (\"shouldn't\", \"should not\"), (\"wasn't\", \"was not\"), (\"weren't\", \"were not\"),\n",
        "            (\"hasn't\", \"has not\"), (\"hadn't\", \"had not\"),\n",
        "            \n",
        "            (\"we'd\", \"we would\"), (\"he'd\", \"he would\"), (\"you'd\", \"you would\"), (\"they'd\", \"they would\"), \n",
        "            (\"who'd\", \"who would\"), (\"wouldn't\", \"would not\"),\n",
        "            \n",
        "            (\"i'll\", \"i will\"), (\"you'll\", \"you will\"), (\"he'll\", \"he will\"), (\"she'll\", \"she will\"),\n",
        "            (\"it'll\", \"it will\"), (\"we'll\", \"we will\"), (\"they'll\", \"they will\"),\n",
        "            \n",
        "            (\"i've\", \"i have\"), (\"you've\", \"you have\"), (\"we've\", \"we have\"), (\"they've\", \"they've\"),\n",
        "            (\"&\", \" and \")\n",
        "           ]\n",
        "\n",
        "def sub_contractions(text):\n",
        "    new_text = text\n",
        "    for r in replaces:\n",
        "        new_text = re.sub(f\"{r[0]}\", f\"{r[1]}\", new_text)\n",
        "    return new_text\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess_text(text):\n",
        "    if type(text) is float:  #Comprobando valores nulos, expresados como un float NaN\n",
        "        ret_text = []\n",
        "    else:\n",
        "        new_text = text.lower()\n",
        "        new_text = sub_contractions(new_text)\n",
        "        new_text = re.sub(\"[^A-Za-zÀ-ÖØ-öø-ÿ0-9 ]\", \"\", new_text)\n",
        "        \n",
        "        tok_text = word_tokenize(new_text)\n",
        "        stop_words = list(stopwords.words(\"english\"))\n",
        "        tok_text = [word for word in tok_text if word not in stop_words]\n",
        "        tok_text = [lemmatizer.lemmatize(word) for word in tok_text]\n",
        "        ret_text = tok_text\n",
        "        \n",
        "        \"\"\" Processing feedback\n",
        "        joint_text = \" \".join(tok_text)\n",
        "        print(new_text)\n",
        "        print(joint_text)\n",
        "        print() #\"\"\"\n",
        "        \n",
        "    return ret_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmr2qqpF7ihL",
        "outputId": "1bb81d8d-f75d-4632-ec48-f2fcf16a6529"
      },
      "source": [
        "'''TITLE'''\n",
        "\n",
        "preprocessed[\"title\"] = df[\"title\"].apply(preprocess_text)\n",
        "preprocessed[\"title\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 [toy, story]\n",
              "1                    [jumanji]\n",
              "2         [grumpier, old, men]\n",
              "3            [waiting, exhale]\n",
              "4    [father, bride, part, ii]\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xq3ZxpFeiQH"
      },
      "source": [
        "### 1.3.3 Tagline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmQjjC3Meram"
      },
      "source": [
        "Para la columna ``tagline``, la cual es de tipo texto, también se deberá llevar a cabo procesamiento de lenguaje natural.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnOHEc4j7ihL",
        "outputId": "e472be8b-06f8-439e-b29a-f42fb2d35faa"
      },
      "source": [
        "'''TAGLINE'''\n",
        "\n",
        "preprocessed[\"tagline\"] = df[\"tagline\"].apply(preprocess_text)\n",
        "preprocessed[\"tagline\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                   []\n",
              "1                    [roll, dice, unleash, excitement]\n",
              "2    [still, yelling, still, fighting, still, ready...\n",
              "3            [friend, people, let, never, let, forget]\n",
              "4            [world, back, normal, he, surprise, life]\n",
              "Name: tagline, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnjEXyq0hByT"
      },
      "source": [
        "### 1.3.4 Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aMtZofLhRMT"
      },
      "source": [
        "También con la columna ``overview``, se debe llevar a cabo de la misma forma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkIPSqlP7ihM",
        "outputId": "1a1c42f7-1f82-4d5d-ee75-09758e16fc62"
      },
      "source": [
        "'''OVERVIEW'''\n",
        "\n",
        "preprocessed[\"overview\"] = df[\"overview\"].apply(preprocess_text)\n",
        "preprocessed[\"overview\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [led, woody, andys, toy, live, happily, room, ...\n",
              "1    [sibling, judy, peter, discover, enchanted, bo...\n",
              "2    [family, wedding, reignites, ancient, feud, ne...\n",
              "3    [cheated, mistreated, stepped, woman, holding,...\n",
              "4    [george, bank, recovered, daughter, wedding, r...\n",
              "Name: overview, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byCwuUZP7ihM"
      },
      "source": [
        "#Fecha dejar a nulo, no eliminar\n",
        "#Pais / idioma variables categoricas, agrupar en regiones y one hot encoding\n",
        "#Objetivo es convertir en variables numericas, añadiendo columnas por one hot encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_8kPNoaikKy"
      },
      "source": [
        "### 1.3.5 Vote count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG7eXvHpjTqi"
      },
      "source": [
        "Para liminamos las filas con valores nulos. Si el numero de votos es menor a 1 no es útil, puesto que una pelicula sin votos no sirve para deducir en función de la media de votos de una pelicula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKSRqnO_7ihM",
        "outputId": "d4445957-2fb3-479d-a117-ef9cce93f3c4"
      },
      "source": [
        "'''VOTE_COUNT'''\n",
        "\n",
        "preprocessed[\"vote_count\"] = df.drop(df[df.vote_count.isna()].index, inplace=False)[\"vote_count\"].astype(\"int32\")\n",
        "preprocessed = preprocessed[preprocessed.vote_count >= 1]\n",
        "preprocessed[\"vote_count\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5415.0\n",
              "1    2413.0\n",
              "2      92.0\n",
              "3      34.0\n",
              "4     173.0\n",
              "Name: vote_count, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTTco25_kYzD"
      },
      "source": [
        "### 1.3.6 Vote average"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jx8zPN-mErs"
      },
      "source": [
        "Eliminamos las filas con valores nulos de la columna ``vote_average``. Las filas anteriores, es decir, que tengan votos significativos, considerar todos los votos (hay filas que tienen una media de 0 pero ningun voto, por lo que no son válidas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znyM_pPa7ihN",
        "outputId": "2f4b571e-5b5f-4c78-f42d-d69a593efd42"
      },
      "source": [
        "'''VOTE_AVERAGE'''\n",
        "\n",
        "preprocessed[\"vote_average\"] = df.drop(df[df.vote_average.isna()].index, inplace=False)[\"vote_average\"]\n",
        "preprocessed[\"vote_average\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7.7\n",
              "1    6.9\n",
              "2    6.5\n",
              "3    6.1\n",
              "4    5.7\n",
              "Name: vote_average, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGVBeHqcnRYB"
      },
      "source": [
        "### 1.3.7 Release date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeegnuPhntNO"
      },
      "source": [
        "Eliminamos las filas con valores nulos de esta columna. La columna de las fechas estaba en string (probablemente debido a los valores erroneos que había al principio) así que la convertimos en una columna de tipo datetime.\r\n",
        "\r\n",
        "Podemos dejarlos como están o bien agrupar los años para extraer conclusiones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fokrJc3m7ihN",
        "outputId": "631d4376-4102-4ad3-dfc7-a34832a02f70"
      },
      "source": [
        "'''RELEASE_DATE'''\n",
        "\n",
        "preprocessed[\"release_date\"] = df.drop(df[df.release_date.isna()].index, inplace=False)[\"release_date\"]\n",
        "preprocessed[\"release_date\"] = pd.to_datetime(preprocessed[\"release_date\"])\n",
        "preprocessed[\"release_date\"].head()\n",
        "\n",
        "#df_years = preprocessed['release_date'].groupby(preprocessed.release_date.dt.year)\n",
        "#print(df_years.first())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   1995-10-30\n",
              "1   1995-12-15\n",
              "2   1995-12-22\n",
              "3   1995-12-22\n",
              "4   1995-02-10\n",
              "Name: release_date, dtype: datetime64[ns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9RYST6KpEKW"
      },
      "source": [
        "### 1.3.8 Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS-ZsTXipJja"
      },
      "source": [
        "Eliminamos las filas con valores nulos y se borran los que tienen valor 0 porque no tiene sentido que una pelicula tenga 0 minutos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ51y-I87ihO",
        "outputId": "5c6e2a0f-090d-4831-b256-f88949df6970"
      },
      "source": [
        "'''RUNTIME'''\n",
        "\n",
        "preprocessed[\"runtime\"] = df.drop(df[df.runtime.isna()].index, inplace=False)[\"runtime\"]\n",
        "preprocessed = preprocessed[preprocessed.runtime >= 1]\n",
        "preprocessed[\"runtime\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     81.0\n",
              "1    104.0\n",
              "2    101.0\n",
              "3    127.0\n",
              "4    106.0\n",
              "Name: runtime, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj1AADlspsez"
      },
      "source": [
        "### 1.3.9 Original language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usD8uBzVpxos"
      },
      "source": [
        "Para elegir los idiomas validos vamos a ver los 6 más usados y juntar los otros en la categoria resto.\r\n",
        "\r\n",
        "\r\n",
        "Cambiar filas con idiomas inválidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEl2K06-7ihO",
        "outputId": "1278a78c-ffe7-4198-ffb6-43686171b9be"
      },
      "source": [
        "'''ORIGINAL LANGUAGE'''\n",
        "\n",
        "idiomas_validos = {'en', 'fr', 'it', 'ja', 'de', 'es'}\n",
        "\n",
        "def preprocess_language(text):\n",
        "    if text in idiomas_validos:\n",
        "        return text\n",
        "    else:\n",
        "        return \"other\"\n",
        "\n",
        "preprocessed[\"original_language\"] = df[\"original_language\"].apply(preprocess_language)\n",
        "preprocessed[\"original_language\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "en       29572\n",
              "other     5195\n",
              "fr        2226\n",
              "ja        1282\n",
              "it        1134\n",
              "de         927\n",
              "es         848\n",
              "Name: original_language, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF7z7aWkqETM"
      },
      "source": [
        "Para elegir los idiomas validos vamos a ver los 6 más usados y hacer un one hot encoding con los que aparezcan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG9h0IlB7ihP",
        "outputId": "5e7862a9-459c-4dd8-97de-8db2fb9ed3d6"
      },
      "source": [
        "def language_counts(rows):\n",
        "    languages_dict = {}\n",
        "    \n",
        "    for row in rows:\n",
        "        try:\n",
        "            languages = ast.literal_eval(row)\n",
        "            \n",
        "            for lang in languages:\n",
        "                code = lang[\"iso_639_1\"]\n",
        "                \n",
        "                if code in languages_dict.keys():\n",
        "                    languages_dict[code] += 1\n",
        "                else:\n",
        "                    languages_dict[code] = 1\n",
        "        except Exception as e:\n",
        "            continue\n",
        "            \n",
        "    sorted_counts = sorted(languages_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_counts\n",
        "\n",
        "\n",
        "\n",
        "def treat_languages(df, best_languages):\n",
        "    for lang in best_languages:\n",
        "        df[f'spoken_lang_{lang}'] = 0\n",
        "    df[f'spoken_lang_other'] = 0\n",
        "    \n",
        "    for i, row in df.iterrows():\n",
        "        try:\n",
        "            language_list = ast.literal_eval(row['spoken_languages'])\n",
        "            for language_dict in language_list:\n",
        "                code = language_dict['iso_639_1']\n",
        "                if code in best_languages:\n",
        "                    df.iloc[i, df.columns.get_loc(f'spoken_lang_{code}')] = 1\n",
        "                else:\n",
        "                    df.iloc[i, df.columns.get_loc(f'spoken_lang_other')] = 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "\n",
        "lang_counts = language_counts(df[\"spoken_languages\"])\n",
        "lang_valid = [lang_counts[i][0] for i in range(7)]\n",
        "lang_valid.append(\"other\")\n",
        "\n",
        "preprocessed['spoken_languages'] = df['spoken_languages']\n",
        "treat_languages(preprocessed, lang_valid)\n",
        "preprocessed.drop(['spoken_languages'], axis=1, inplace=True)\n",
        "preprocessed.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tagline</th>\n",
              "      <th>overview</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>release_date</th>\n",
              "      <th>runtime</th>\n",
              "      <th>original_language</th>\n",
              "      <th>spoken_lang_en</th>\n",
              "      <th>spoken_lang_fr</th>\n",
              "      <th>spoken_lang_de</th>\n",
              "      <th>spoken_lang_es</th>\n",
              "      <th>spoken_lang_it</th>\n",
              "      <th>spoken_lang_ja</th>\n",
              "      <th>spoken_lang_ru</th>\n",
              "      <th>spoken_lang_other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[toy, story]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[led, woody, andys, toy, live, happily, room, ...</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1995-10-30</td>\n",
              "      <td>81.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[jumanji]</td>\n",
              "      <td>[roll, dice, unleash, excitement]</td>\n",
              "      <td>[sibling, judy, peter, discover, enchanted, bo...</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1995-12-15</td>\n",
              "      <td>104.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[grumpier, old, men]</td>\n",
              "      <td>[still, yelling, still, fighting, still, ready...</td>\n",
              "      <td>[family, wedding, reignites, ancient, feud, ne...</td>\n",
              "      <td>92.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>101.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[waiting, exhale]</td>\n",
              "      <td>[friend, people, let, never, let, forget]</td>\n",
              "      <td>[cheated, mistreated, stepped, woman, holding,...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>127.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[father, bride, part, ii]</td>\n",
              "      <td>[world, back, normal, he, surprise, life]</td>\n",
              "      <td>[george, bank, recovered, daughter, wedding, r...</td>\n",
              "      <td>173.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1995-02-10</td>\n",
              "      <td>106.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       title  \\\n",
              "0               [toy, story]   \n",
              "1                  [jumanji]   \n",
              "2       [grumpier, old, men]   \n",
              "3          [waiting, exhale]   \n",
              "4  [father, bride, part, ii]   \n",
              "\n",
              "                                             tagline  \\\n",
              "0                                                 []   \n",
              "1                  [roll, dice, unleash, excitement]   \n",
              "2  [still, yelling, still, fighting, still, ready...   \n",
              "3          [friend, people, let, never, let, forget]   \n",
              "4          [world, back, normal, he, surprise, life]   \n",
              "\n",
              "                                            overview  vote_count  \\\n",
              "0  [led, woody, andys, toy, live, happily, room, ...      5415.0   \n",
              "1  [sibling, judy, peter, discover, enchanted, bo...      2413.0   \n",
              "2  [family, wedding, reignites, ancient, feud, ne...        92.0   \n",
              "3  [cheated, mistreated, stepped, woman, holding,...        34.0   \n",
              "4  [george, bank, recovered, daughter, wedding, r...       173.0   \n",
              "\n",
              "   vote_average release_date  runtime original_language  spoken_lang_en  \\\n",
              "0           7.7   1995-10-30     81.0                en               1   \n",
              "1           6.9   1995-12-15    104.0                en               1   \n",
              "2           6.5   1995-12-22    101.0                en               1   \n",
              "3           6.1   1995-12-22    127.0                en               1   \n",
              "4           5.7   1995-02-10    106.0                en               1   \n",
              "\n",
              "   spoken_lang_fr  spoken_lang_de  spoken_lang_es  spoken_lang_it  \\\n",
              "0               0               0               0               0   \n",
              "1               1               0               0               0   \n",
              "2               0               0               0               0   \n",
              "3               0               0               0               0   \n",
              "4               0               0               0               0   \n",
              "\n",
              "   spoken_lang_ja  spoken_lang_ru  spoken_lang_other  \n",
              "0               0               0                  0  \n",
              "1               0               0                  0  \n",
              "2               0               0                  0  \n",
              "3               0               0                  0  \n",
              "4               0               0                  0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vrEgU0UqYLX"
      },
      "source": [
        "### 1.3.10 Genre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XSNJu3sqhwF"
      },
      "source": [
        "Para elegir los generos validos vamos a ver los 5 mas usados y juntar los otros en la categoria resto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IiI6F8N7ihQ",
        "outputId": "df41ba5c-4bd9-4566-81a6-2352baa7d118"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "#print(pd.isnull(df).any())\n",
        "print(df[\"genres\"].value_counts(dropna=False))\n",
        "\n",
        "#Camabiar filas con generos inválidos\n",
        "generos_validos = {'1', '2', '3', '4', '5'}\n",
        "\n",
        "for nodo in df:\n",
        "   if genres not in generos_validos \n",
        "      genres = other\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def genre_counts(rows):\n",
        "    genre_dict = {}\n",
        "    \n",
        "    for row in rows:\n",
        "        try:\n",
        "            genres = ast.literal_eval(row)\n",
        "            \n",
        "            for genre in genres:\n",
        "                name = genre[\"name\"]\n",
        "                \n",
        "                if name in genre_dict.keys():\n",
        "                    genre_dict[name] += 1\n",
        "                else:\n",
        "                    genre_dict[name] = 1\n",
        "        except Exception as e:\n",
        "            continue\n",
        "            \n",
        "    sorted_counts = sorted(genre_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_counts\n",
        "\n",
        "\n",
        "\n",
        "def treat_genres(df, valid_genres):\n",
        "    for genre in valid_genres:\n",
        "        df[genre] = 0\n",
        "    \n",
        "    for i, row in df.iterrows():\n",
        "        try:\n",
        "            genre_list = ast.literal_eval(row['genres'])\n",
        "            for genre_dict in genre_list:\n",
        "                name = genre_dict['name']\n",
        "                \n",
        "                if name in valid_genres:\n",
        "                    df.iloc[i, df.columns.get_loc(genre)] = 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "\n",
        "genre_counts = genre_counts(df[\"genres\"])\n",
        "genre_valid = [genre[0] for genre in genre_counts]\n",
        "\n",
        "preprocessed['genres'] = df['genres']\n",
        "treat_genres(preprocessed, genre_valid)\n",
        "preprocessed.drop(['genres'], axis=1, inplace=True)\n",
        "preprocessed.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tagline</th>\n",
              "      <th>overview</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>release_date</th>\n",
              "      <th>runtime</th>\n",
              "      <th>original_language</th>\n",
              "      <th>spoken_lang_en</th>\n",
              "      <th>spoken_lang_fr</th>\n",
              "      <th>...</th>\n",
              "      <th>Family</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>Fantasy</th>\n",
              "      <th>Animation</th>\n",
              "      <th>Foreign</th>\n",
              "      <th>Music</th>\n",
              "      <th>History</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "      <th>TV Movie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[toy, story]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[led, woody, andys, toy, live, happily, room, ...</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1995-10-30</td>\n",
              "      <td>81.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[jumanji]</td>\n",
              "      <td>[roll, dice, unleash, excitement]</td>\n",
              "      <td>[sibling, judy, peter, discover, enchanted, bo...</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1995-12-15</td>\n",
              "      <td>104.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[grumpier, old, men]</td>\n",
              "      <td>[still, yelling, still, fighting, still, ready...</td>\n",
              "      <td>[family, wedding, reignites, ancient, feud, ne...</td>\n",
              "      <td>92.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>101.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[waiting, exhale]</td>\n",
              "      <td>[friend, people, let, never, let, forget]</td>\n",
              "      <td>[cheated, mistreated, stepped, woman, holding,...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>127.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[father, bride, part, ii]</td>\n",
              "      <td>[world, back, normal, he, surprise, life]</td>\n",
              "      <td>[george, bank, recovered, daughter, wedding, r...</td>\n",
              "      <td>173.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1995-02-10</td>\n",
              "      <td>106.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       title  \\\n",
              "0               [toy, story]   \n",
              "1                  [jumanji]   \n",
              "2       [grumpier, old, men]   \n",
              "3          [waiting, exhale]   \n",
              "4  [father, bride, part, ii]   \n",
              "\n",
              "                                             tagline  \\\n",
              "0                                                 []   \n",
              "1                  [roll, dice, unleash, excitement]   \n",
              "2  [still, yelling, still, fighting, still, ready...   \n",
              "3          [friend, people, let, never, let, forget]   \n",
              "4          [world, back, normal, he, surprise, life]   \n",
              "\n",
              "                                            overview  vote_count  \\\n",
              "0  [led, woody, andys, toy, live, happily, room, ...      5415.0   \n",
              "1  [sibling, judy, peter, discover, enchanted, bo...      2413.0   \n",
              "2  [family, wedding, reignites, ancient, feud, ne...        92.0   \n",
              "3  [cheated, mistreated, stepped, woman, holding,...        34.0   \n",
              "4  [george, bank, recovered, daughter, wedding, r...       173.0   \n",
              "\n",
              "   vote_average release_date  runtime original_language  spoken_lang_en  \\\n",
              "0           7.7   1995-10-30     81.0                en               1   \n",
              "1           6.9   1995-12-15    104.0                en               1   \n",
              "2           6.5   1995-12-22    101.0                en               1   \n",
              "3           6.1   1995-12-22    127.0                en               1   \n",
              "4           5.7   1995-02-10    106.0                en               1   \n",
              "\n",
              "   spoken_lang_fr  ...  Family  Mystery  Fantasy  Animation  Foreign  Music  \\\n",
              "0               0  ...       0        0        0          0        0      0   \n",
              "1               1  ...       0        0        0          0        0      0   \n",
              "2               0  ...       0        0        0          0        0      0   \n",
              "3               0  ...       0        0        0          0        0      0   \n",
              "4               0  ...       0        0        0          0        0      0   \n",
              "\n",
              "   History  War  Western  TV Movie  \n",
              "0        0    0        0         1  \n",
              "1        0    0        0         1  \n",
              "2        0    0        0         1  \n",
              "3        0    0        0         1  \n",
              "4        0    0        0         1  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao1C4erD7ihR"
      },
      "source": [
        "#Tenemos que elegir entre tocar o no el presupuesto, si lo dejamos tal cual o en 4 categorias que habia dudas \n",
        "#(que sean super produccion, gran produccion, produccion normal y produccion bajo presupuesto por ejemplo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzbt_fu8q0w5"
      },
      "source": [
        "### 1.3.11 Production companies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYdgHP2_q-l4"
      },
      "source": [
        "En cuanto a la columna `production_companies`, esta es una columna con diccionarios de compañías, por lo que se hará será coger el 'id' de cada compañía productora de la película y contar las apariciones de cada compañía para, posteriormente, en esa misma columna poner el valor de las ocurrencias (popularidad) máxima de las compañías involucradas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGYnt2hm7ihS"
      },
      "source": [
        "'''PRODUCTION_COMPANIES'''\n",
        "\n",
        "def popularity_companies(rows):\n",
        "    companies_popularity = {}\n",
        "    for row in rows:\n",
        "        try:\n",
        "            companies = ast.literal_eval(row)\n",
        "            for company in companies:\n",
        "                if company['id'] in companies_popularity.keys():\n",
        "                    companies_popularity[company['id']] += 1\n",
        "                else:\n",
        "                    companies_popularity[company['id']] = 1\n",
        "        except Exception:\n",
        "            continue\n",
        "    return companies_popularity\n",
        "\n",
        "companies_popularity = popularity_companies(df['production_companies'])\n",
        "\n",
        "def treat_companies(row):\n",
        "    max_popularity = 0\n",
        "    try:\n",
        "        companies = ast.literal_eval(row)\n",
        "        for company in companies:\n",
        "            if int(companies_popularity[company['id']]) > max_popularity:\n",
        "                max_popularity = companies_popularity[company['id']]\n",
        "        return max_popularity\n",
        "    except Exception:\n",
        "        return max_popularity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enILuAqg7ihT",
        "outputId": "ed269b31-e414-444f-ad02-a6d6ec2fc62c"
      },
      "source": [
        "preprocessed['production_companies'] = df['production_companies'].apply(treat_companies)\n",
        "preprocessed['production_companies'].head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       52\n",
              "1      197\n",
              "2     1250\n",
              "3      836\n",
              "4      225\n",
              "5     1250\n",
              "6     1003\n",
              "7      263\n",
              "8      830\n",
              "9      279\n",
              "10     431\n",
              "11     431\n",
              "12     830\n",
              "13      84\n",
              "14    1076\n",
              "15     830\n",
              "16     448\n",
              "17     183\n",
              "18    1250\n",
              "19     431\n",
              "Name: production_companies, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07J5jXqsrJBt"
      },
      "source": [
        "### 1.3.11 Production countries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1FH4m-KrP-c"
      },
      "source": [
        "Para `production_countries`, esta es una columna de diccionarios de compañías, por lo que el proceso sera coger los id's de cada compañía y crear una lista de los siete países que más aparecen. Esto se convertirá en columna de one hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7se_QBV07ihT",
        "outputId": "ddad1a63-443e-4acf-a957-28e59dc1226d"
      },
      "source": [
        "'''PRODUCTION_COUNTRIES'''\n",
        "\n",
        "def popularity_countries(rows):\n",
        "    countries_popularity = {}\n",
        "    \n",
        "    for row in rows:\n",
        "        try:\n",
        "            countries = ast.literal_eval(row)\n",
        "            for country in countries:\n",
        "                if country['iso_3166_1'] in countries_popularity.keys():\n",
        "                    countries_popularity[country['iso_3166_1']] += 1\n",
        "                else:\n",
        "                    countries_popularity[country['iso_3166_1']] = 1\n",
        "        except:\n",
        "            continue\n",
        "            \n",
        "    countries = sorted(countries_popularity.items(), key=lambda x: x[1], reverse=True)[:7]\n",
        "    best_countries = []\n",
        "    \n",
        "    for country in countries:\n",
        "        best_countries.append(country[0])\n",
        "        \n",
        "    return best_countries\n",
        "\n",
        "\n",
        "def treat_countries(df, best_countries):\n",
        "    for country in best_countries:\n",
        "        df[f'production_{country}'] = 0\n",
        "    df['production_other'] = 0\n",
        "        \n",
        "    for i, row in df.iterrows():\n",
        "        try:\n",
        "            countries = ast.literal_eval(row['production_countries'])\n",
        "            for country in countries:\n",
        "                if country['iso_3166_1'] in best_countries:\n",
        "                    df.iloc[i, df.columns.get_loc(f'production_{country[\"iso_3166_1\"]}')] = 1\n",
        "                else:\n",
        "                    df.iloc[i, df.columns.get_loc('production_other')] = 1\n",
        "        except:\n",
        "            continue\n",
        "            \n",
        "\n",
        "popular_countries = popularity_countries(df['production_countries'])\n",
        "preprocessed[\"production_countries\"] = df['production_countries']\n",
        "treat_countries(preprocessed, popular_countries)\n",
        "preprocessed.drop(['production_countries'], axis=1, inplace=True)\n",
        "preprocessed.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tagline</th>\n",
              "      <th>overview</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>release_date</th>\n",
              "      <th>runtime</th>\n",
              "      <th>original_language</th>\n",
              "      <th>spoken_lang_en</th>\n",
              "      <th>spoken_lang_fr</th>\n",
              "      <th>...</th>\n",
              "      <th>TV Movie</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_US</th>\n",
              "      <th>production_GB</th>\n",
              "      <th>production_FR</th>\n",
              "      <th>production_DE</th>\n",
              "      <th>production_IT</th>\n",
              "      <th>production_CA</th>\n",
              "      <th>production_JP</th>\n",
              "      <th>production_other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[toy, story]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[led, woody, andys, toy, live, happily, room, ...</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1995-10-30</td>\n",
              "      <td>81.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[jumanji]</td>\n",
              "      <td>[roll, dice, unleash, excitement]</td>\n",
              "      <td>[sibling, judy, peter, discover, enchanted, bo...</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1995-12-15</td>\n",
              "      <td>104.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>197</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[grumpier, old, men]</td>\n",
              "      <td>[still, yelling, still, fighting, still, ready...</td>\n",
              "      <td>[family, wedding, reignites, ancient, feud, ne...</td>\n",
              "      <td>92.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>101.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[waiting, exhale]</td>\n",
              "      <td>[friend, people, let, never, let, forget]</td>\n",
              "      <td>[cheated, mistreated, stepped, woman, holding,...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>127.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>836</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[father, bride, part, ii]</td>\n",
              "      <td>[world, back, normal, he, surprise, life]</td>\n",
              "      <td>[george, bank, recovered, daughter, wedding, r...</td>\n",
              "      <td>173.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1995-02-10</td>\n",
              "      <td>106.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       title  \\\n",
              "0               [toy, story]   \n",
              "1                  [jumanji]   \n",
              "2       [grumpier, old, men]   \n",
              "3          [waiting, exhale]   \n",
              "4  [father, bride, part, ii]   \n",
              "\n",
              "                                             tagline  \\\n",
              "0                                                 []   \n",
              "1                  [roll, dice, unleash, excitement]   \n",
              "2  [still, yelling, still, fighting, still, ready...   \n",
              "3          [friend, people, let, never, let, forget]   \n",
              "4          [world, back, normal, he, surprise, life]   \n",
              "\n",
              "                                            overview  vote_count  \\\n",
              "0  [led, woody, andys, toy, live, happily, room, ...      5415.0   \n",
              "1  [sibling, judy, peter, discover, enchanted, bo...      2413.0   \n",
              "2  [family, wedding, reignites, ancient, feud, ne...        92.0   \n",
              "3  [cheated, mistreated, stepped, woman, holding,...        34.0   \n",
              "4  [george, bank, recovered, daughter, wedding, r...       173.0   \n",
              "\n",
              "   vote_average release_date  runtime original_language  spoken_lang_en  \\\n",
              "0           7.7   1995-10-30     81.0                en               1   \n",
              "1           6.9   1995-12-15    104.0                en               1   \n",
              "2           6.5   1995-12-22    101.0                en               1   \n",
              "3           6.1   1995-12-22    127.0                en               1   \n",
              "4           5.7   1995-02-10    106.0                en               1   \n",
              "\n",
              "   spoken_lang_fr  ...  TV Movie  production_companies  production_US  \\\n",
              "0               0  ...         1                    52              1   \n",
              "1               1  ...         1                   197              1   \n",
              "2               0  ...         1                  1250              1   \n",
              "3               0  ...         1                   836              1   \n",
              "4               0  ...         1                   225              1   \n",
              "\n",
              "   production_GB  production_FR  production_DE  production_IT  production_CA  \\\n",
              "0              0              0              0              0              0   \n",
              "1              0              0              0              0              0   \n",
              "2              0              0              0              0              0   \n",
              "3              0              0              0              0              0   \n",
              "4              0              0              0              0              0   \n",
              "\n",
              "   production_JP  production_other  \n",
              "0              0                 0  \n",
              "1              0                 0  \n",
              "2              0                 0  \n",
              "3              0                 0  \n",
              "4              0                 0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWL1SHNc7ihU",
        "outputId": "5aa9d4fc-055a-42e2-889e-3f83c74177af"
      },
      "source": [
        "df['production_countries'][6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[{'iso_3166_1': 'DE', 'name': 'Germany'}, {'iso_3166_1': 'US', 'name': 'United States of America'}]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB4VCJs3r-nN"
      },
      "source": [
        "### 1.3.12 Revenue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nAumSyKu8og"
      },
      "source": [
        "Lo que haremos será recuperar valores perdidos de esta columna. NO podremos hacerlo mediante los valores anteriores ni posteriores, ya que no hay relación temporal en las entradas del dataset. Tampoco utilizaremos la media ya que es sensible a los outliers. Por lo que se utilizará la mediana para rellenar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDNfoY0y7ihU"
      },
      "source": [
        "'''REVENUE'''\n",
        "\n",
        "#Eliminar estos valores o guardarlos en otro dataframe de pruebas\n",
        "df['revenue'].fillna(df['revenue'].median, inplace=True)\n",
        "pd.isnull(df).any()\"\"\"\n",
        "\n",
        "preprocessed[\"revenue\"] = df[\"revenue\"]\n",
        "\n",
        "revenue_valor = preprocessed[preprocessed[\"revenue\"] > 0]\n",
        "revenue_cero = preprocessed[preprocessed[\"revenue\"] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2q5jP8s7ihU",
        "outputId": "6d859647-38f6-45ea-d5a4-306dbd1246db"
      },
      "source": [
        "print(len(revenue_valor))\n",
        "print(len(revenue_cero))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7349\n",
            "33835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZpeo43Q7ihV",
        "outputId": "3d60aad6-f322-468d-e42f-6d5740e340f7"
      },
      "source": [
        "revenue_valor.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tagline</th>\n",
              "      <th>overview</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>release_date</th>\n",
              "      <th>runtime</th>\n",
              "      <th>original_language</th>\n",
              "      <th>spoken_lang_en</th>\n",
              "      <th>spoken_lang_fr</th>\n",
              "      <th>...</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_US</th>\n",
              "      <th>production_GB</th>\n",
              "      <th>production_FR</th>\n",
              "      <th>production_DE</th>\n",
              "      <th>production_IT</th>\n",
              "      <th>production_CA</th>\n",
              "      <th>production_JP</th>\n",
              "      <th>production_other</th>\n",
              "      <th>revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[toy, story]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[led, woody, andys, toy, live, happily, room, ...</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1995-10-30</td>\n",
              "      <td>81.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373554033.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[jumanji]</td>\n",
              "      <td>[roll, dice, unleash, excitement]</td>\n",
              "      <td>[sibling, judy, peter, discover, enchanted, bo...</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1995-12-15</td>\n",
              "      <td>104.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>197</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>262797249.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[waiting, exhale]</td>\n",
              "      <td>[friend, people, let, never, let, forget]</td>\n",
              "      <td>[cheated, mistreated, stepped, woman, holding,...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1995-12-22</td>\n",
              "      <td>127.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>836</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>81452156.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[father, bride, part, ii]</td>\n",
              "      <td>[world, back, normal, he, surprise, life]</td>\n",
              "      <td>[george, bank, recovered, daughter, wedding, r...</td>\n",
              "      <td>173.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1995-02-10</td>\n",
              "      <td>106.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>76578911.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[heat]</td>\n",
              "      <td>[los, angeles, crime, saga]</td>\n",
              "      <td>[obsessive, master, thief, neil, mccauley, lea...</td>\n",
              "      <td>1886.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>1995-12-15</td>\n",
              "      <td>170.0</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187436818.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       title                                    tagline  \\\n",
              "0               [toy, story]                                         []   \n",
              "1                  [jumanji]          [roll, dice, unleash, excitement]   \n",
              "3          [waiting, exhale]  [friend, people, let, never, let, forget]   \n",
              "4  [father, bride, part, ii]  [world, back, normal, he, surprise, life]   \n",
              "5                     [heat]                [los, angeles, crime, saga]   \n",
              "\n",
              "                                            overview  vote_count  \\\n",
              "0  [led, woody, andys, toy, live, happily, room, ...      5415.0   \n",
              "1  [sibling, judy, peter, discover, enchanted, bo...      2413.0   \n",
              "3  [cheated, mistreated, stepped, woman, holding,...        34.0   \n",
              "4  [george, bank, recovered, daughter, wedding, r...       173.0   \n",
              "5  [obsessive, master, thief, neil, mccauley, lea...      1886.0   \n",
              "\n",
              "   vote_average release_date  runtime original_language  spoken_lang_en  \\\n",
              "0           7.7   1995-10-30     81.0                en               1   \n",
              "1           6.9   1995-12-15    104.0                en               1   \n",
              "3           6.1   1995-12-22    127.0                en               1   \n",
              "4           5.7   1995-02-10    106.0                en               1   \n",
              "5           7.7   1995-12-15    170.0                en               1   \n",
              "\n",
              "   spoken_lang_fr  ...  production_companies  production_US  production_GB  \\\n",
              "0               0  ...                    52              1              0   \n",
              "1               1  ...                   197              1              0   \n",
              "3               0  ...                   836              1              0   \n",
              "4               0  ...                   225              1              0   \n",
              "5               0  ...                  1250              1              0   \n",
              "\n",
              "   production_FR  production_DE  production_IT  production_CA  production_JP  \\\n",
              "0              0              0              0              0              0   \n",
              "1              0              0              0              0              0   \n",
              "3              0              0              0              0              0   \n",
              "4              0              0              0              0              0   \n",
              "5              0              0              0              0              0   \n",
              "\n",
              "   production_other      revenue  \n",
              "0                 0  373554033.0  \n",
              "1                 0  262797249.0  \n",
              "3                 0   81452156.0  \n",
              "4                 0   76578911.0  \n",
              "5                 0  187436818.0  \n",
              "\n",
              "[5 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8x65nifwBjG"
      },
      "source": [
        "## 1.4 Saving processed datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMvBxkXW7ihV"
      },
      "source": [
        "revenue_valor.to_csv(\"movies_training.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4hUiJP_7ihV"
      },
      "source": [
        "revenue_cero.to_csv(\"movies_testing.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVoR0sU7ihV",
        "outputId": "2f8e1d90-30a0-4cd4-ca67-6a610e3c1dc6"
      },
      "source": [
        "for r in preprocessed:\n",
        "    print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title\n",
            "tagline\n",
            "overview\n",
            "vote_count\n",
            "vote_average\n",
            "release_date\n",
            "runtime\n",
            "original_language\n",
            "spoken_lang_en\n",
            "spoken_lang_fr\n",
            "spoken_lang_de\n",
            "spoken_lang_es\n",
            "spoken_lang_it\n",
            "spoken_lang_ja\n",
            "spoken_lang_ru\n",
            "spoken_lang_other\n",
            "Drama\n",
            "Comedy\n",
            "Thriller\n",
            "Romance\n",
            "Action\n",
            "Horror\n",
            "Crime\n",
            "Documentary\n",
            "Adventure\n",
            "Science Fiction\n",
            "Family\n",
            "Mystery\n",
            "Fantasy\n",
            "Animation\n",
            "Foreign\n",
            "Music\n",
            "History\n",
            "War\n",
            "Western\n",
            "TV Movie\n",
            "production_companies\n",
            "production_US\n",
            "production_GB\n",
            "production_FR\n",
            "production_DE\n",
            "production_IT\n",
            "production_CA\n",
            "production_JP\n",
            "production_other\n",
            "revenue\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}